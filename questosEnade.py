import streamlit as st
import requests
from datetime import datetime
from io import BytesIO
from bs4 import BeautifulSoup
from openai import OpenAI
import google.generativeai as genai
import PyPDF2
from docx import Document
import pandas as pd

# --- CONSTANTES ---
AREAS_ENADE = {
    "Ci√™ncias Sociais Aplicadas": ["Direito", "Administra√ß√£o", "Ci√™ncias Cont√°beis", "Jornalismo", "Publicidade e Propaganda", "Turismo"],
    "Engenharias": ["Engenharia de Software", "Engenharia Civil", "Engenharia de Produ√ß√£o", "Engenharia El√©trica", "Engenharia Mec√¢nica"],
    "Ci√™ncias da Sa√∫de": ["Medicina", "Enfermagem", "Farm√°cia", "Fisioterapia", "Nutri√ß√£o"],
    "Ci√™ncias Humanas": ["Pedagogia", "Hist√≥ria", "Letras", "Psicologia"],
}
BLOOM_LEVELS = ["Lembrar", "Compreender", "Aplicar", "Analisar", "Avaliar", "Criar"]
BLOOM_VERBS = {
    "Lembrar": ["definir", "listar", "identificar", "recordar", "nomear", "reconhecer"],
    "Compreender": ["explicar", "resumir", "interpretar", "classificar", "descrever", "discutir"],
    "Aplicar": ["usar", "implementar", "executar", "demonstrar", "resolver", "calcular"],
    "Analisar": ["diferenciar", "organizar", "atribuir", "comparar", "examinar", "categorizar"],
    "Avaliar": ["julgar", "criticar", "justificar", "avaliar", "defender", "recomendar"],
    "Criar": ["projetar", "construir", "formular", "sintetizar", "planejar", "desenvolver"]
}

# --- CONFIG STREAMLIT ---
st.set_page_config(page_title="Gerador de Quest√µes ENADE v3.4", page_icon="üéì", layout="wide")

# --- ESTADO INICIAL ---
st.session_state.setdefault("api_key", None)
st.session_state.setdefault("text_base", "")
st.session_state.setdefault("ref_final", "")
st.session_state.setdefault("search_results", [])
st.session_state.setdefault("perfil", "")
st.session_state.setdefault("competencia", "")
st.session_state.setdefault("questoes_geradas", []) 
st.session_state.setdefault("selected_index", 0)
st.session_state.setdefault("fonte_info", {})

# --- SIDEBAR ---
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√£o IA")
    provedor = st.selectbox("Provedor", ["OpenAI (GPT)", "Google (Gemini)"])
    st.session_state.api_key = st.text_input("Chave de API", type="password", value=st.session_state.api_key)
    if provedor.startswith("OpenAI"):
        modelo = st.selectbox("Modelo GPT", ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"])
    else:
        modelo = st.selectbox("Modelo Gemini", ["gemini-1.5-flash-latest", "gemini-1.5-pro-latest"])
    st.info("Vers√£o 3.4: Busca de not√≠cias e inclus√£o do texto-base corrigidas.")

    st.header("üìú Hist√≥rico da Sess√£o")
    if not st.session_state.questoes_geradas:
        st.caption("Nenhuma quest√£o gerada nesta sess√£o.")
    else:
        titulos = [q["titulo"] for q in st.session_state.questoes_geradas]
        selected_title = st.radio(
            "Selecione uma quest√£o para ver/editar:",
            options=titulos,
            index=st.session_state.selected_index,
            key="historico_radio"
        )
        st.session_state.selected_index = titulos.index(selected_title)

if not st.session_state.api_key:
    st.warning("Informe a chave de API na lateral para continuar.")
    st.stop()

# --- FUN√á√ïES AUXILIARES ---
@st.cache_data(ttl=3600)
def extrair_conteudo_url(url: str):
    try:
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        title = soup.title.string if soup.title else ""
        author_meta = soup.find("meta", attrs={"name": "author"})
        author = author_meta["content"] if author_meta else ""
        for tag in soup(["script", "style", "nav", "footer", "header", "aside"]): tag.decompose()
        return " ".join(soup.stripped_strings), title, author
    except: return None, None, None

def extrair_texto_upload(upload):
    try:
        if upload.type == "application/pdf":
            reader = PyPDF2.PdfReader(BytesIO(upload.read()))
            return "".join(p.extract_text() or "" for p in reader.pages)
        elif upload.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
            doc = Document(BytesIO(upload.read()))
            return "\n".join(p.text for p in doc.paragraphs)
        return None
    except Exception as e:
        st.error(f"Erro ao ler o arquivo: {e}")
        return None

def search_articles(query, num=5, search_type='web'):
    try:
        headers = {"User-Agent": "Mozilla/5.0", "Accept-Language": "pt-BR,pt;q=0.9"}
        params = {"q": query, "hl": "pt-BR", "gl": "br", "num": num}
        if search_type == 'news':
            params['tbm'] = 'nws' 
        r = requests.get("https://www.google.com/search", headers=headers, params=params, timeout=10)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        results = []
        # --- SELETORES ATUALIZADOS PARA BUSCA DE NOT√çCIAS ---
        for block in soup.select("div.mCBkyc, div.WlydOe, div.SoaBEf"):
            a = block.find("a", href=True)
            title_element = block.find("h3") or block.find('div', role='heading')
            if a and title_element:
                results.append({"title": title_element.get_text(), "url": a["href"]})
            if len(results) >= num: break
        return results
    except Exception as e:
        st.error(f"Erro na busca: {e}")
        return []

def chamar_llm(prompts, prov, mdl, temperature=0.7, max_tokens=2000):
    try:
        if prov.startswith("OpenAI"):
            client = OpenAI(api_key=st.session_state.api_key)
            r = client.chat.completions.create(model=mdl, messages=prompts, temperature=temperature, max_tokens=max_tokens, response_format={"type": "text"})
            return r.choices[0].message.content.strip()
        else:
            genai.configure(api_key=st.session_state.api_key)
            cfg = genai.GenerationConfig(temperature=temperature, max_output_tokens=max_tokens, response_mime_type="text/plain")
            m = genai.GenerativeModel(mdl)
            prompt_text = "\n".join(f"**{m['role']}**: {m['content']}" for m in prompts)
            resp = m.generate_content(prompt_text, generation_config=cfg)
            return resp.text
    except Exception as e:
        st.error(f"Erro ao chamar a API: {e}")
        return None

# --- LAYOUT PRINCIPAL ---
st.title("üéì Gerador de Quest√µes ENADE v3.4")
st.markdown("Bem-vindo ao gerador interativo. Siga os passos para criar, analisar e refinar suas quest√µes.")

col_input, col_output = st.columns(2, gap="large")

with col_input:
    st.header("1. Defini√ß√µes da Quest√£o")
    
    with st.container(border=True):
        st.subheader("Escopo e Tipo")
        c1, c2 = st.columns(2)
        area = c1.selectbox("√Årea", list(AREAS_ENADE.keys()))
        curso = c2.selectbox("Curso", AREAS_ENADE[area])
        assunto = st.text_input("Assunto central", "")
        
        tipos_questao = {
            "M√∫ltipla Escolha Tradicional": "Enunciado com 5 alternativas (A, B, C, D, E), sendo apenas uma correta.",
            "Complementa√ß√£o": "Frase com uma ou mais lacunas (___) que devem ser preenchidas por uma das alternativas.",
            "Afirma√ß√£o-Raz√£o": "Duas asser√ß√µes (I e II) ligadas por 'PORQUE'. O aluno avalia a veracidade de ambas e a rela√ß√£o entre elas.",
            "Resposta M√∫ltipla": "Apresenta v√°rias afirmativas (I, II, III...). O aluno deve selecionar a alternativa que indica quais est√£o corretas."
        }
        question_type = st.selectbox(
            "Tipo de quest√£o", 
            options=list(tipos_questao.keys()),
            format_func=lambda k: f"{k}: {tipos_questao[k]}"
        )

    with st.container(border=True):
        st.subheader("Defini√ß√£o Pedag√≥gica")
        st.session_state.perfil = st.text_input("Perfil do egresso a ser avaliado", st.session_state.perfil, help="Descreva o que se espera do profissional formado.")
        st.session_state.competencia = st.text_input("Compet√™ncia a ser avaliada", st.session_state.competencia, help="Descreva a habilidade que a quest√£o deve medir.")

    with st.container(border=True):
        st.subheader("Fonte do Texto-Base")
        opc_fonte = st.radio("Selecione a fonte:", ["Gerar com IA", "Fornecer um texto-base"], horizontal=True, key="opc_fonte")
        
        if opc_fonte == "Gerar com IA":
            if st.session_state.perfil and st.session_state.competencia and assunto:
                if st.button("Gerar Contextualiza√ß√£o com IA", use_container_width=True):
                    with st.spinner("A IA est√° criando um texto-base contextualizado..."):
                        prompt_contexto = [
                            {"role": "system", "content": f"Voc√™ √© um docente especialista do curso de {curso} que cria textos-base para quest√µes do ENADE. Os textos devem ser contextualizados, apresentar uma situa√ß√£o-problema e ser perfeitamente alinhados √†s diretrizes pedag√≥gicas."},
                            {"role": "user", "content": f"Elabore um texto-base (entre 150 e 250 palavras) para uma quest√£o do ENADE sobre '{assunto}'. O texto deve ser uma situa√ß√£o-problema voltada a um egresso com o perfil: '{st.session_state.perfil}'. A avalia√ß√£o focar√° na compet√™ncia: '{st.session_state.competencia}'. O texto deve ser t√©cnico e denso. N√£o inclua enunciado ou alternativas, apenas o texto-base."}
                        ]
                        tb = chamar_llm(prompt_contexto, provedor, modelo, temperature=0.6, max_tokens=400)
                        if tb:
                            st.session_state.text_base = tb
                            st.session_state.ref_final = "Texto gerado por IA."
                            st.success("Texto-base gerado!")
            else:
                st.warning("Preencha o Assunto, Perfil e Compet√™ncia para gerar o texto-base.")
        else:
            tab_colar, tab_upload, tab_busca = st.tabs(["Colar Texto", "Upload de Arquivo (PDF/DOCX)", "Busca na Web"])

            with tab_colar:
                st.session_state.text_base = st.text_area("Cole o texto-base aqui:", height=150, key="tb_colar")
                st.session_state.ref_final = st.text_input("Refer√™ncia ABNT do texto colado (se aplic√°vel):", key="ref_colar")

            with tab_upload:
                up = st.file_uploader("Envie um arquivo PDF ou DOCX", type=['pdf', 'docx'])
                if up:
                    with st.spinner("Extraindo e resumindo o conte√∫do do arquivo..."):
                        txt_extraido = extrair_texto_upload(up)
                        if txt_extraido:
                            prompt_resumo = [
                                {"role": "system", "content": "Voc√™ √© um especialista em resumir textos para serem usados como base em quest√µes do ENADE."},
                                {"role": "user", "content": f"Resuma o texto a seguir em um par√°grafo coeso de at√© 200 palavras, focando nos pontos essenciais para uma quest√£o sobre '{assunto}' no curso de {curso}.\n\nTEXTO:\n{txt_extraido[:4000]}"}
                            ]
                            st.session_state.text_base = chamar_llm(prompt_resumo, provedor, modelo, temperature=0.4)
                            st.session_state.ref_final = f"Texto adaptado de '{up.name}'."
                            st.success("Arquivo processado e resumido!")
                        else:
                            st.error("N√£o foi poss√≠vel extrair texto do arquivo.")

            with tab_busca:
                # --- BOT√ÉO DE BUSCA SIMPLIFICADO ---
                if st.button("üì∞ Buscar Not√≠cias", use_container_width=True, key="search_news_btn"):
                    with st.spinner(f"Buscando not√≠cias sobre '{assunto}'..."):
                        st.session_state.search_results = search_articles(f'"{assunto}"', search_type='news')
                        if not st.session_state.search_results:
                            st.warning("Nenhuma not√≠cia encontrada.")
                
                if st.session_state.search_results:
                    opts = [f"{r['title']}" for r in st.session_state.search_results]
                    sel_idx = st.selectbox("Selecione um resultado para usar como base:", options=range(len(opts)), format_func=lambda i: opts[i])
                    if st.button("‚ñ∂Ô∏è Usar este conte√∫do", key="use_search_btn"):
                        art = st.session_state.search_results[sel_idx]
                        with st.spinner(f"Extraindo e resumindo '{art['title']}'..."):
                            cont, tit, aut = extrair_conteudo_url(art["url"])
                            if cont:
                                prompt_resumo_web = [
                                    {"role": "system", "content": "Voc√™ resume conte√∫dos da web para serem usados como base em quest√µes do ENADE."},
                                    {"role": "user", "content": f"Resuma o conte√∫do a seguir em um par√°grafo (at√© 200 palavras) que sirva como situa√ß√£o-problema sobre '{assunto}'.\n\nConte√∫do:\n{cont[:4000]}"}
                                ]
                                st.session_state.text_base = chamar_llm(prompt_resumo_web, provedor, modelo, temperature=0.4)
                                st.session_state.fonte_info = {"titulo": tit, "autor": aut, "veiculo": art["url"].split("/")[2], "link": art["url"]}
                                hoje = datetime.now()
                                meses = ["jan.","fev.","mar.","abr.","mai.","jun.","jul.","ago.","set.","out.","nov.","dez."]
                                acesso = f"{hoje.day} {meses[hoje.month-1]}. {hoje.year}"
                                st.session_state.ref_final = f"Adaptado de: {aut if aut else 'Autor desconhecido'}. **{tit}**. {st.session_state.fonte_info['veiculo']}. Dispon√≠vel em: <{art['url']}>. Acesso em: {acesso}."
                                st.success("Conte√∫do da web processado!")
                            else:
                                st.error("Falha ao extrair conte√∫do da URL.")
        st.text_area("Texto-Base a ser utilizado:", st.session_state.text_base, height=150, key="tb_final_view", disabled=True)
    
    with st.container(border=True):
        st.subheader("Par√¢metros de Gera√ß√£o")
        with st.form("frm_gerar"):
            niv = st.select_slider("N√≠vel Bloom", options=BLOOM_LEVELS, value="Analisar")
            dificuldade = st.slider("N√≠vel de dificuldade", 1, 5, 3)
            gerar = st.form_submit_button("üöÄ Gerar Nova Quest√£o", use_container_width=True, type="primary")

            if gerar:
                if not st.session_state.text_base:
                    st.error("√â necess√°rio ter um Texto-Base para gerar a quest√£o.")
                else:
                    with st.spinner("Gerando quest√£o e an√°lise de qualidade..."):
                        # --- PROMPT AJUSTADO PARA N√ÉO REPETIR O TEXTO-BASE ---
                        sys_p_geracao = """
                        Voc√™ √© um docente especialista em produzir quest√µes no estilo ENADE.
                        A partir do TEXTO-BASE e da REFER√äNCIA que ser√£o fornecidos no prompt do usu√°rio, sua tarefa √© criar **apenas** o conte√∫do da quest√£o (ENUNCIADO, ALTERNATIVAS, GABARITO, JUSTIFICATIVAS).
                        Siga as regras:
                        - A quest√£o deve ser in√©dita e alinhada √† encomenda.
                        - O enunciado deve ser claro e afirmativo. Proibido pedir a 'incorreta'.
                        - Para m√∫ltipla escolha, crie 4 distratores plaus√≠veis.
                        - **N√ÉO** inclua o TEXTO-BASE ou a REFER√äNCIA na sua resposta. Gere apenas o que foi pedido.
                        """
                        usr_p_geracao = f"""
                        GERAR CONTE√öDO DA QUEST√ÉO ENADE:
                        - √Årea: {area}, Curso: {curso}, Assunto: {assunto}
                        - Perfil: {st.session_state.perfil}, Compet√™ncia: {st.session_state.competencia}
                        - Tipo: {question_type}, Dificuldade: {dificuldade}/5, N√≠vel Bloom: {niv}
                        - Use o seguinte formato de sa√≠da EXATAMENTE:
                        ENUNCIADO: [Seu enunciado aqui]
                        ALTERNATIVAS:
                        A. [Alternativa A]
                        B. [Alternativa B]
                        C. [Alternativa C]
                        D. [Alternativa D]
                        E. [Alternativa E]
                        GABARITO: [Letra X]
                        JUSTIFICATIVAS:
                        A. [Justificativa para A]
                        B. [Justificativa para B]
                        C. [Justificativa para C]
                        D. [Justificativa para D]
                        E. [Justificativa para E]

                        ---
                        TEXTO-BASE PARA SUA AN√ÅLISE (N√ÉO COPIAR NA RESPOSTA):
                        {st.session_state.text_base}
                        REFER√äNCIA (N√ÉO COPIAR NA RESPOSTA):
                        {st.session_state.ref_final}
                        """
                        questao_parcial = chamar_llm([{"role": "system", "content": sys_p_geracao}, {"role": "user", "content": usr_p_geracao}], provedor, modelo)

                        if questao_parcial:
                            # --- MONTAGEM DA QUEST√ÉO FINAL COM O TEXTO-BASE ---
                            ref_formatada = f"Refer√™ncia: {st.session_state.ref_final}\n\n" if st.session_state.ref_final else ""
                            questao_completa = f"TEXTO-BASE\n\n{st.session_state.text_base}\n\n{ref_formatada}{questao_parcial}"

                            sys_p_analise = """
                            Voc√™ √© um avaliador de itens do ENADE, um especialista em pedagogia e avalia√ß√£o. 
                            Sua tarefa √© fornecer uma an√°lise cr√≠tica e construtiva da quest√£o fornecida.
                            Seja direto e objetivo. Use bullet points.
                            AVALIE OS SEGUINTES PONTOS:
                            - **Clareza e Pertin√™ncia:** O enunciado √© claro? Ele se conecta bem ao texto-base?
                            - **Qualidade dos Distratores:** As alternativas incorretas (distratores) s√£o plaus√≠veis? Elas testam erros conceituais comuns ou s√£o f√°ceis demais?
                            - **Alinhamento Pedag√≥gico:** A quest√£o realmente avalia a compet√™ncia, o n√≠vel de dificuldade e o n√≠vel de Bloom solicitados?
                            - **Potencial de Melhoria:** D√™ uma sugest√£o para melhorar a quest√£o.
                            """
                            analise_qualidade = chamar_llm([{"role": "system", "content": sys_p_analise}, {"role": "user", "content": questao_completa}], provedor, modelo, temperature=0.3)

                            if analise_qualidade:
                                novo_item = {
                                    "titulo": f"Q{len(st.session_state.questoes_geradas) + 1}: {curso} - {assunto[:25]}...",
                                    "texto_completo": questao_completa,
                                    "analise_qualidade": analise_qualidade,
                                    "contexto": {"area": area, "curso": curso, "assunto": assunto, "perfil": st.session_state.perfil, "competencia": st.session_state.competencia, "texto_base": st.session_state.text_base}
                                }
                                st.session_state.questoes_geradas.append(novo_item)
                                st.session_state.selected_index = len(st.session_state.questoes_geradas) - 1
                                st.success("Quest√£o e an√°lise geradas!")
                                st.rerun()

with col_output:
    st.header("2. An√°lise e Refinamento")

    if not st.session_state.questoes_geradas:
        st.info("A quest√£o gerada, junto com sua an√°lise de qualidade e op√ß√µes de refinamento, aparecer√° aqui.")
    else:
        q_selecionada = st.session_state.questoes_geradas[st.session_state.selected_index]
        st.subheader(f"Visualizando: {q_selecionada['titulo']}")
        tab_view, tab_analise, tab_refino = st.tabs(["üìù Quest√£o", "üîç An√°lise de Qualidade (IA)", "‚ú® Refinamento Iterativo (IA)"])

        with tab_view:
            st.text_area("Texto da Quest√£o", value=q_selecionada["texto_completo"], height=500, key=f"q_view_{st.session_state.selected_index}")
            c1, c2 = st.columns(2)
            c1.download_button("üìÑ Baixar esta quest√£o (.txt)", q_selecionada["texto_completo"], f"{q_selecionada['titulo']}.txt", use_container_width=True)
            df_all = pd.DataFrame([{"titulo": q["titulo"], "questao": q["texto_completo"], "analise": q["analise_qualidade"]} for q in st.session_state.questoes_geradas])
            to_xl = BytesIO()
            df_all.to_excel(to_xl, index=False, sheet_name="Quest√µes")
            to_xl.seek(0)
            c2.download_button("üì• Baixar todas (.xlsx)", to_xl, "banco_completo_enade.xlsx", use_container_width=True)
        with tab_analise:
            st.info("Esta an√°lise foi gerada por uma IA especialista para ajudar na valida√ß√£o da quest√£o.")
            st.markdown(q_selecionada["analise_qualidade"])
        with tab_refino:
            st.warning("A√ß√µes de refinamento modificar√£o a quest√£o atual. A vers√£o original ser√° perdida.")
            r_c1, r_c2, r_c3 = st.columns(3)
            if r_c1.button("ü§î Tornar Mais Dif√≠cil", use_container_width=True, key=f"b_dificil_{st.session_state.selected_index}"):
                with st.spinner("Refinando para aumentar a dificuldade..."):
                    prompt_refino = f"Reescreva a quest√£o a seguir para torn√°-la significativamente mais dif√≠cil, mantendo o mesmo gabarito.\n\nQUEST√ÉO ATUAL:\n{q_selecionada['texto_completo']}"
                    texto_refinado = chamar_llm([{"role": "user", "content": prompt_refino}], provedor, modelo)
                    st.session_state.questoes_geradas[st.session_state.selected_index]["texto_completo"] = texto_refinado
                    st.rerun()
            if r_c2.button("‚úçÔ∏è Simplificar o Enunciado", use_container_width=True, key=f"b_simplificar_{st.session_state.selected_index}"):
                with st.spinner("Refinando para simplificar o enunciado..."):
                     prompt_refino = f"Reescreva apenas o ENUNCIADO da quest√£o a seguir para torn√°-lo mais claro e direto, sem alterar o gabarito.\n\nQUEST√ÉO ATUAL:\n{q_selecionada['texto_completo']}"
                     texto_refinado = chamar_llm([{"role": "user", "content": prompt_refino}], provedor, modelo)
                     st.session_state.questoes_geradas[st.session_state.selected_index]["texto_completo"] = texto_refinado
                     st.rerun()
            if r_c3.button("üîÑ Regenerar Alternativas", use_container_width=True, key=f"b_alternativas_{st.session_state.selected_index}"):
                with st.spinner("Regenerando as alternativas..."):
                    prompt_refino = f"Mantenha o TEXTO-BASE e o ENUNCIADO da quest√£o a seguir, mas gere um conjunto completamente novo de 5 ALTERNATIVAS, GABARITO e suas respectivas JUSTIFICATIVAS.\n\nQUEST√ÉO ATUAL:\n{q_selecionada['texto_completo']}"
                    texto_refinado = chamar_llm([{"role": "user", "content": prompt_refino}], provedor, modelo)
                    st.session_state.questoes_geradas[st.session_state.selected_index]["texto_completo"] = texto_refinado
                    st.rerun()

# Bot√£o para limpar a sess√£o
if st.sidebar.button("üî¥ Encerrar e Limpar Sess√£o", use_container_width=True):
    keys_to_clear = list(st.session_state.keys())
    for key in keys_to_clear:
        del st.session_state[key]
    st.rerun()
