import streamlit as st
import requests
from datetime import datetime
from io import BytesIO
from bs4 import BeautifulSoup
from openai import OpenAI
import google.generativeai as genai
import PyPDF2
from docx import Document
import pandas as pd

# --- CONSTANTES ---
AREAS_ENADE = {
    "Ci√™ncias Sociais Aplicadas": ["Direito", "Administra√ß√£o", "Ci√™ncias Cont√°beis", "Jornalismo", "Publicidade e Propaganda", "Turismo"],
    "Engenharias": ["Engenharia de Software", "Engenharia Civil", "Engenharia de Produ√ß√£o", "Engenharia El√©trica", "Engenharia Mec√¢nica"],
    "Ci√™ncias da Sa√∫de": ["Medicina", "Enfermagem", "Farm√°cia", "Fisioterapia", "Nutri√ß√£o"],
    "Ci√™ncias Humanas": ["Pedagogia", "Hist√≥ria", "Letras", "Psicologia"],
}
BLOOM_LEVELS = ["Lembrar", "Compreender", "Aplicar", "Analisar", "Avaliar", "Criar"]
BLOOM_VERBS = {
    "Lembrar": ["definir", "listar", "identificar", "recordar", "nomear", "reconhecer"],
    "Compreender": ["explicar", "resumir", "interpretar", "classificar", "descrever", "discutir"],
    "Aplicar": ["usar", "implementar", "executar", "demonstrar", "resolver", "calcular"],
    "Analisar": ["diferenciar", "organizar", "atribuir", "comparar", "examinar", "categorizar"],
    "Avaliar": ["julgar", "criticar", "justificar", "avaliar", "defender", "recomendar"],
    "Criar": ["projetar", "construir", "formular", "sintetizar", "planejar", "desenvolver"]
}

# --- CONFIG STREAMLIT ---
st.set_page_config(page_title="Gerador de Quest√µes ENADE v3.0", page_icon="üéì", layout="wide")

# --- ESTADO INICIAL ---
# Inicializa todos os estados necess√°rios para a sess√£o
st.session_state.setdefault("api_key", None)
st.session_state.setdefault("text_base", "")
st.session_state.setdefault("auto", False)
st.session_state.setdefault("ref_final", "")
st.session_state.setdefault("search_results", [])
st.session_state.setdefault("perfil", "")
st.session_state.setdefault("competencia", "")
# Novos estados para hist√≥rico e interatividade
st.session_state.setdefault("questoes_geradas", []) # Lista de dicion√°rios com todos os dados da quest√£o
st.session_state.setdefault("selected_index", 0)

# --- SIDEBAR ---
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√£o IA")
    provedor = st.selectbox("Provedor", ["OpenAI (GPT)", "Google (Gemini)"])
    st.session_state.api_key = st.text_input("Chave de API", type="password", value=st.session_state.api_key)
    if provedor.startswith("OpenAI"):
        modelo = st.selectbox("Modelo GPT", ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"])
    else:
        modelo = st.selectbox("Modelo Gemini", ["gemini-1.5-flash-latest", "gemini-1.5-pro-latest"])
    st.info("Vers√£o 3.0: Refinamento interativo, an√°lise de qualidade e hist√≥rico de sess√£o.")

    # NOVO: HIST√ìRICO DE QUEST√ïES NA BARRA LATERAL
    st.header("üìú Hist√≥rico da Sess√£o")
    if not st.session_state.questoes_geradas:
        st.caption("Nenhuma quest√£o gerada nesta sess√£o.")
    else:
        titulos = [q["titulo"] for q in st.session_state.questoes_geradas]
        selected_title = st.radio(
            "Selecione uma quest√£o para ver/editar:",
            options=titulos,
            index=st.session_state.selected_index,
            key="historico_radio"
        )
        st.session_state.selected_index = titulos.index(selected_title)

if not st.session_state.api_key:
    st.warning("Informe a chave de API na lateral para continuar.")
    st.stop()

# --- FUN√á√ïES AUXILIARES ---
@st.cache_data(ttl=3600)
def extrair_conteudo_url(url: str):
    try:
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        title = soup.title.string if soup.title else ""
        for tag in soup(["script", "style", "nav", "footer", "header", "aside"]): tag.decompose()
        return " ".join(soup.stripped_strings), title, ""
    except: return None, None, None

def chamar_llm(prompts, prov, mdl, temperature=0.7, max_tokens=2000):
    # (Fun√ß√£o original sem modifica√ß√µes)
    try:
        if prov.startswith("OpenAI"):
            client = OpenAI(api_key=st.session_state.api_key)
            r = client.chat.completions.create(model=mdl, messages=prompts, temperature=temperature, max_tokens=max_tokens, response_format={"type": "text"})
            return r.choices[0].message.content.strip()
        else:
            genai.configure(api_key=st.session_state.api_key)
            cfg = genai.GenerationConfig(temperature=temperature, max_output_tokens=max_tokens, response_mime_type="text/plain")
            m = genai.GenerativeModel(mdl)
            prompt_text = "\n".join(f"**{m['role']}**: {m['content']}" for m in prompts)
            resp = m.generate_content(prompt_text, generation_config=cfg)
            return resp.text
    except Exception as e:
        st.error(f"Erro ao chamar a API: {e}")
        return None

# --- LAYOUT PRINCIPAL ---
st.title("üéì Gerador de Quest√µes ENADE v3.0")
st.markdown("Bem-vindo ao gerador interativo. Siga os passos para criar, analisar e refinar suas quest√µes.")

# --- COLUNAS PARA INPUTS E OUTPUTS ---
col_input, col_output = st.columns(2, gap="large")

with col_input:
    st.header("1. Defini√ß√µes da Quest√£o")
    
    with st.container(border=True):
        st.subheader("Escopo e Tipo")
        c1, c2 = st.columns(2)
        area = c1.selectbox("√Årea", list(AREAS_ENADE.keys()))
        curso = c2.selectbox("Curso", AREAS_ENADE[area])
        assunto = st.text_input("Assunto central", "")
        
        tipos_questao = {
            "M√∫ltipla Escolha Tradicional": "apresentar enunciado + alternativas (1 correta)",
            "Complementa√ß√£o": "frase com lacuna '___', alternativas completam",
            "Afirma√ß√£o-Raz√£o": "afirma√ß√£o e raz√£o, avaliar verdade e justificativa",
            "Resposta M√∫ltipla": "selecionar/agrupar v√°rias corretas"
        }
        question_type = st.selectbox("Tipo de quest√£o", options=list(tipos_questao.keys()))

    with st.container(border=True):
        st.subheader("Defini√ß√£o Pedag√≥gica")
        perfil = st.text_input("Perfil do egresso a ser avaliado", st.session_state.perfil, help="Descreva o que se espera do profissional formado.")
        competencia = st.text_input("Compet√™ncia a ser avaliada", st.session_state.competencia, help="Descreva a habilidade que a quest√£o deve medir.")

    with st.container(border=True):
        st.subheader("Fonte do Texto-Base")
        opc = st.radio("Selecione a fonte:", ["Gerar com IA", "Fornecer um texto-base"], horizontal=True)
        
        if opc == "Gerar com IA":
            st.session_state.auto = True
            if perfil and competencia:
                if st.button("Gerar Contextualiza√ß√£o com IA", use_container_width=True):
                    # L√≥gica de gera√ß√£o de texto-base... (semelhante √† anterior)
                    st.session_state.text_base = "Texto gerado pela IA com base no perfil e compet√™ncia." # Placeholder
            else:
                st.warning("Preencha o Perfil e a Compet√™ncia para gerar o texto-base.")
        else:
            st.session_state.auto = False
            # L√≥gica de upload ou busca na web... (semelhante √† anterior)
            st.session_state.text_base = st.text_area("Cole aqui seu texto-base ou use as buscas (ainda n√£o implementado nesta vers√£o).", height=150)
            st.session_state.ref_final = st.text_input("Refer√™ncia ABNT do texto-base (se aplic√°vel):")
    
    with st.container(border=True):
        st.subheader("Par√¢metros de Gera√ß√£o")
        with st.form("frm_gerar"):
            niv = st.select_slider("N√≠vel Bloom", options=BLOOM_LEVELS, value="Analisar")
            dificuldade = st.slider("N√≠vel de dificuldade", 1, 5, 3)
            gerar = st.form_submit_button("üöÄ Gerar Nova Quest√£o", use_container_width=True, type="primary")

            if gerar:
                if not st.session_state.text_base:
                    st.error("√â necess√°rio ter um Texto-Base para gerar a quest√£o.")
                else:
                    with st.spinner("Gerando quest√£o e an√°lise de qualidade... Isso pode levar um momento."):
                        # 1. GERAR A QUEST√ÉO
                        sys_p_geracao = "Voc√™ √© um docente especialista em produzir quest√µes no estilo ENADE..." # Prompt de gera√ß√£o
                        usr_p_geracao = f"""
                        GERAR QUEST√ÉO ENADE:
                        - √Årea: {area}, Curso: {curso}, Assunto: {assunto}
                        - Perfil: {perfil}, Compet√™ncia: {competencia}
                        - Tipo: {question_type}, Dificuldade: {dificuldade}/5, N√≠vel Bloom: {niv}
                        - TEXTO-BASE: {st.session_state.text_base}
                        - REFER√äNCIA: {st.session_state.ref_final if not st.session_state.auto else 'Texto gerado por IA.'}
                        - FORMATO DE SA√çDA: ENUNCIADO: ..., ALTERNATIVAS: A..., B..., GABARITO:..., JUSTIFICATIVAS:...
                        """
                        questao_gerada = chamar_llm([{"role": "system", "content": sys_p_geracao}, {"role": "user", "content": usr_p_geracao}], provedor, modelo)

                        # 2. GERAR A AN√ÅLISE DE QUALIDADE
                        sys_p_analise = """
                        Voc√™ √© um avaliador de itens do ENADE, um especialista em pedagogia e avalia√ß√£o. Sua tarefa √© fornecer uma an√°lise cr√≠tica e construtiva da quest√£o fornecida.
                        Seja direto e objetivo. Use bullet points.
                        AVALIE OS SEGUINTES PONTOS:
                        - **Clareza e Pertin√™ncia:** O enunciado √© claro? Ele se conecta bem ao texto-base?
                        - **Qualidade dos Distratores:** As alternativas incorretas (distratores) s√£o plaus√≠veis? Elas testam erros conceituais comuns ou s√£o f√°ceis demais?
                        - **Alinhamento Pedag√≥gico:** A quest√£o realmente avalia a compet√™ncia, o n√≠vel de dificuldade e o n√≠vel de Bloom solicitados?
                        - **Potencial de Melhoria:** D√™ uma sugest√£o para melhorar a quest√£o.
                        """
                        analise_qualidade = chamar_llm([{"role": "system", "content": sys_p_analise}, {"role": "user", "content": questao_gerada}], provedor, modelo, temperature=0.3)

                        if questao_gerada and analise_qualidade:
                            novo_item = {
                                "titulo": f"Q{len(st.session_state.questoes_geradas) + 1}: {curso} - {assunto[:25]}...",
                                "texto_completo": questao_gerada,
                                "analise_qualidade": analise_qualidade,
                                # Armazenar contexto para refinamento
                                "contexto": {"area": area, "curso": curso, "assunto": assunto, "perfil": perfil, "competencia": competencia, "texto_base": st.session_state.text_base}
                            }
                            st.session_state.questoes_geradas.append(novo_item)
                            st.session_state.selected_index = len(st.session_state.questoes_geradas) - 1
                            st.success("Quest√£o e an√°lise geradas!")
                            st.rerun() # Atualiza o radio da sidebar

with col_output:
    st.header("2. An√°lise e Refinamento")

    if not st.session_state.questoes_geradas:
        st.info("A quest√£o gerada, junto com sua an√°lise de qualidade e op√ß√µes de refinamento, aparecer√° aqui.")
    else:
        q_selecionada = st.session_state.questoes_geradas[st.session_state.selected_index]
        
        st.subheader(f"Visualizando: {q_selecionada['titulo']}")

        tab_view, tab_analise, tab_refino = st.tabs(["üìù Quest√£o", "üîç An√°lise de Qualidade (IA)", "‚ú® Refinamento Iterativo (IA)"])

        with tab_view:
            st.text_area("Texto da Quest√£o", value=q_selecionada["texto_completo"], height=500, key=f"q_view_{st.session_state.selected_index}")
            c1, c2 = st.columns(2)
            c1.download_button("üìÑ Baixar esta quest√£o (.txt)", q_selecionada["texto_completo"], f"{q_selecionada['titulo']}.txt", use_container_width=True)
            
            # Preparar para download de todas
            df_all = pd.DataFrame(st.session_state.questoes_geradas)
            to_xl = BytesIO()
            df_all.to_excel(to_xl, index=False, sheet_name="Quest√µes")
            to_xl.seek(0)
            c2.download_button("üì• Baixar todas (.xlsx)", to_xl, "banco_completo_enade.xlsx", use_container_width=True)

        with tab_analise:
            st.info("Esta an√°lise foi gerada por uma IA especialista para ajudar na valida√ß√£o da quest√£o.")
            st.markdown(q_selecionada["analise_qualidade"])

        with tab_refino:
            st.warning("A√ß√µes de refinamento modificar√£o a quest√£o atual. A vers√£o original ser√° perdida.")
            
            r_c1, r_c2, r_c3 = st.columns(3)

            if r_c1.button("ü§î Tornar Mais Dif√≠cil", use_container_width=True):
                instrucao = "Reescreva a quest√£o a seguir para torn√°-la significativamente mais dif√≠cil. Aumente a complexidade do enunciado, torne os distratores mais sutis e exija um n√≠vel de racioc√≠nio mais elevado, mantendo o mesmo gabarito."
                with st.spinner("Refinando para aumentar a dificuldade..."):
                    prompt_refino = f"{instrucao}\n\nQUEST√ÉO ATUAL:\n{q_selecionada['texto_completo']}"
                    texto_refinado = chamar_llm([{"role": "user", "content": prompt_refino}], provedor, modelo)
                    st.session_state.questoes_geradas[st.session_state.selected_index]["texto_completo"] = texto_refinado
                    st.rerun()

            if r_c2.button("‚úçÔ∏è Simplificar o Enunciado", use_container_width=True):
                instrucao = "Reescreva apenas o ENUNCIADO da quest√£o a seguir para torn√°-lo mais claro, direto e objetivo, sem alterar o n√≠vel de dificuldade das alternativas ou o gabarito."
                with st.spinner("Refinando para simplificar o enunciado..."):
                     prompt_refino = f"{instrucao}\n\nQUEST√ÉO ATUAL:\n{q_selecionada['texto_completo']}"
                     texto_refinado = chamar_llm([{"role": "user", "content": prompt_refino}], provedor, modelo)
                     st.session_state.questoes_geradas[st.session_state.selected_index]["texto_completo"] = texto_refinado
                     st.rerun()

            if r_c3.button("üîÑ Regenerar Alternativas", use_container_width=True):
                instrucao = "Mantenha o TEXTO-BASE e o ENUNCIADO da quest√£o a seguir, mas gere um conjunto completamente novo de 5 ALTERNATIVAS, 1 GABARITO e suas respectivas JUSTIFICATIVAS. Crie distratores plaus√≠veis e desafiadores."
                with st.spinner("Regenerando as alternativas..."):
                    prompt_refino = f"{instrucao}\n\nQUEST√ÉO ATUAL:\n{q_selecionada['texto_completo']}"
                    texto_refinado = chamar_llm([{"role": "user", "content": prompt_refino}], provedor, modelo)
                    st.session_state.questoes_geradas[st.session_state.selected_index]["texto_completo"] = texto_refinado
                    st.rerun()

    # Bot√£o para limpar a sess√£o
    if st.sidebar.button("üî¥ Encerrar e Limpar Sess√£o", use_container_width=True):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()
